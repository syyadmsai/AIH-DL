{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: keras in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (1.69.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: rich in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from keras) (0.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn tensorflow keras matplotlib seaborn imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_path = \"C:/Users/SYYAD/Documents/MSAI/AI in Healthcare/NLP/\"  # Change this to your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_file = os.path.join(mimic_path, \"LABEVENTS.csv\")\n",
    "\n",
    "# Load only needed columns\n",
    "df_labs = pd.read_csv(labevents_file, usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"ITEMID\", \"VALUENUM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_file = os.path.join(mimic_path, \"MICROBIOLOGYEVENTS.csv\")\n",
    "\n",
    "# Load data with pathogen information\n",
    "df_micro = pd.read_csv(micro_file, usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"ORG_NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_file = os.path.join(mimic_path, \"PRESCRIPTIONS.csv\")\n",
    "\n",
    "# Load only required columns\n",
    "df_meds = pd.read_csv(prescriptions_file, usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"DRUG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant lab tests for infection risk\n",
    "infection_markers = {\n",
    "    50861: \"wbc_count\",  # White Blood Cell Count\n",
    "    50912: \"creatinine\",  # Kidney Function\n",
    "    50822: \"crp\",  # C-Reactive Protein (infection marker)\n",
    "    50813: \"lactate\"  # Lactate (infection/sepsis indicator)\n",
    "}\n",
    "\n",
    "df_labs = df_labs[df_labs[\"ITEMID\"].isin(infection_markers.keys())]\n",
    "df_labs[\"ITEMID\"] = df_labs[\"ITEMID\"].map(infection_markers)\n",
    "\n",
    "# Pivot table to structure the data\n",
    "df_labs = df_labs.pivot_table(index=[\"SUBJECT_ID\", \"HADM_ID\"], columns=\"ITEMID\", values=\"VALUENUM\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common hospital-acquired infections (e.g., MRSA, Klebsiella, Pseudomonas)\n",
    "hai_pathogens = [\"STAPH AUREUS COAG\", \"ESCHERICHIA COLI\", \"STAPHYLOCOCCUS, COAGULASE NEGATIVE\", \"KLEBSIELLA PNEUMONIAE\", \"PSEUDOMONAS AERUGINOSA\"]\n",
    "\n",
    "# Create infection flag\n",
    "df_micro[\"hai_infection\"] = df_micro[\"ORG_NAME\"].apply(lambda x: 1 if any(pathogen in str(x) for pathogen in hai_pathogens) else 0)\n",
    "\n",
    "# Aggregate to patient level (1 if any infection was found)\n",
    "df_micro = df_micro.groupby([\"SUBJECT_ID\", \"HADM_ID\"])[\"hai_infection\"].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common **antibiotics used for hospital-acquired infections**\n",
    "antibiotics = [\"Vancomycin\", \"Ceftriaxone\", \"Piperacillin\", \"Meropenem\", \"Linezolid\"]\n",
    "\n",
    "# Create antibiotic treatment flag\n",
    "df_meds[\"antibiotic_treatment\"] = df_meds[\"DRUG\"].apply(lambda x: 1 if any(abx in str(x) for abx in antibiotics) else 0)\n",
    "\n",
    "# Aggregate to patient level (1 if any antibiotic was given)\n",
    "df_meds = df_meds.groupby([\"SUBJECT_ID\", \"HADM_ID\"])[\"antibiotic_treatment\"].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge lab results, microbiology data, and medication history\n",
    "df = df_labs.merge(df_micro, on=[\"SUBJECT_ID\", \"HADM_ID\"], how=\"left\")\n",
    "df = df.merge(df_meds, on=[\"SUBJECT_ID\", \"HADM_ID\"], how=\"left\")\n",
    "\n",
    "# Fill missing values with median\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Drop ID columns\n",
    "# df = df.drop(columns=[\"SUBJECT_ID\", \"HADM_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features & target variable\n",
    "features = [\"wbc_count\", \"creatinine\", \"crp\", \"lactate\", \"antibiotic_treatment\"]\n",
    "X = df[features]\n",
    "y = df[\"hai_infection\"]  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE: hai_infection\n",
      "1.0    38691\n",
      "0.0    38691\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"After SMOTE:\", pd.Series(y_resampled).value_counts())  # Check new balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Split dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7794146152355108\n",
      "Random Forest AUC: 0.8571119595089083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.76      0.78      7739\n",
      "         1.0       0.77      0.80      0.78      7738\n",
      "\n",
      "    accuracy                           0.78     15477\n",
      "   macro avg       0.78      0.78      0.78     15477\n",
      "weighted avg       0.78      0.78      0.78     15477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "# Check if there are at least two classes in y_train before calculating AUC\n",
    "if len(np.unique(y_train)) > 1:\n",
    "\tprint(\"Random Forest AUC:\", roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]))\n",
    "else:\n",
    "\tprint(\"Random Forest AUC cannot be calculated because there is only one class in the target variable.\")\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6795244556438587\n",
      "Logistic Regression AUC: 0.7048819256413132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Logistic Regression AUC:\", roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_train shape: (88, 16, 7)\n",
      " y_train shape: (88,)\n"
     ]
    }
   ],
   "source": [
    "TIME_STEPS = 16  # Use past 5 records for each prediction\n",
    "\n",
    "# Convert data into sequences\n",
    "def create_sequences(df, time_steps):\n",
    "    X_seq, y_seq = [], []\n",
    "    \n",
    "    for patient_id in df[\"SUBJECT_ID\"].unique():\n",
    "        patient_data = df[df[\"SUBJECT_ID\"] == patient_id]\n",
    "        features = patient_data.drop(columns=[\"hai_infection\"])  # Drop target column\n",
    "        \n",
    "        for i in range(len(features) - time_steps):\n",
    "            X_seq.append(features.iloc[i:i+time_steps].values)  # Use past `time_steps` records\n",
    "            y_seq.append(patient_data[\"hai_infection\"].iloc[i+time_steps])  # Predict infection at last step\n",
    "            \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X, y = create_sequences(df, TIME_STEPS)\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Print shapes\n",
    "print(f\" X_train shape: {X_train.shape}\")  # (samples, time_steps, features)\n",
    "print(f\" y_train shape: {y_train.shape}\")  # (samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SYYAD\\miniconda3\\envs\\dl_hw\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m69,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,489</span> (513.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,489\u001b[0m (513.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,489</span> (513.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131,489\u001b[0m (513.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 357ms/step - accuracy: 0.6879 - loss: 0.6532 - val_accuracy: 0.7826 - val_loss: 0.5403\n",
      "Epoch 2/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7752 - loss: 0.5491 - val_accuracy: 0.7826 - val_loss: 0.5258\n",
      "Epoch 3/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7674 - loss: 0.5425 - val_accuracy: 0.7826 - val_loss: 0.5278\n",
      "Epoch 4/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7674 - loss: 0.5418 - val_accuracy: 0.7826 - val_loss: 0.5236\n",
      "Epoch 5/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7635 - loss: 0.5449 - val_accuracy: 0.7826 - val_loss: 0.5241\n",
      "Epoch 6/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7479 - loss: 0.5618 - val_accuracy: 0.7826 - val_loss: 0.5254\n",
      "Epoch 7/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7518 - loss: 0.5536 - val_accuracy: 0.7826 - val_loss: 0.5253\n",
      "Epoch 8/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7440 - loss: 0.5694 - val_accuracy: 0.7826 - val_loss: 0.5262\n",
      "Epoch 9/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7713 - loss: 0.5344 - val_accuracy: 0.7826 - val_loss: 0.5238\n",
      "Epoch 10/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7752 - loss: 0.5333 - val_accuracy: 0.7826 - val_loss: 0.5216\n",
      "Epoch 11/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7791 - loss: 0.5200 - val_accuracy: 0.7826 - val_loss: 0.5218\n",
      "Epoch 12/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7674 - loss: 0.5345 - val_accuracy: 0.7826 - val_loss: 0.5208\n",
      "Epoch 13/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7557 - loss: 0.5503 - val_accuracy: 0.7826 - val_loss: 0.5271\n",
      "Epoch 14/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7322 - loss: 0.5639 - val_accuracy: 0.7826 - val_loss: 0.5274\n",
      "Epoch 15/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7791 - loss: 0.5132 - val_accuracy: 0.7826 - val_loss: 0.5195\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
